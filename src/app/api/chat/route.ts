// src/app/api/chat/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY || '');

export async function POST(request: NextRequest) {
  try {
    const { messages } = await request.json();

    if (!messages || messages.length === 0) {
      return NextResponse.json(
        { error: 'Messages are required' },
        { status: 400 }
      );
    }

    // Use gemini-1.5-flash-latest as the correct model name
    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash-latest' });

    const lastMessage = messages[messages.length - 1];
    const conversationHistory = messages
      .slice(0, -1)
      .map((msg: any) => `${msg.role === 'user' ? 'Student' : 'Tutor'}: ${msg.content}`)
      .join('\n');

    const prompt = `You are an AI tutor helping students understand their study materials. You are patient, encouraging, and provide clear explanations.

${conversationHistory ? `Previous conversation:\n${conversationHistory}\n\n` : ''}Student: ${lastMessage.content}

Tutor:`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return NextResponse.json({ message: text });
  } catch (error: any) {
    console.error('Chat API error:', error);
    return NextResponse.json(
      { error: 'Failed to process chat' },
      { status: 500 }
    );
  }
}

